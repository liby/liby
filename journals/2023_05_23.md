- [美国券商嘉信理财开户【图文步骤详解】2022版](https://readingoutpost.com/charles-schwab-open-account/)
	- [嘉信理财(Charles Schwab)Visa提款卡申请](http://www.sugarforex.com/securities/schwab-visa-debit-card.html)
- [CSS 规则可以覆盖通过 JavaScript 设置的样式](https://twitter.com/awesomekling/status/1660319607939375106)
- 通过 https://resend.com/ 结合 https://react.email/ 来发送和设计邮件
- *robots.txt* 是什么
	- *robots.txt* 是一个文本文件，网站管理员通常将其放在网站的根目录下，用以告知搜索引擎的机器人（又称为网络蜘蛛或爬虫）哪些部分的网站是可以爬取的，哪些部分是不能爬取的。
	- 这个文件的标准格式非常简单。例如，如果你想让所有的机器人都能访问你的网站，那么你的 *robots.txt* 文件就应该是这样的：
		- ```
		  User-agent: *
		  Disallow:
		  ```
			- 这里的 `User-agent: *` 表示这个规则适用于所有的机器人，而 `Disallow:` 后面没有跟任何内容，表示没有禁止爬取的部分。
			- 如果你想禁止所有机器人访问你的网站，那么你的 *robots.txt* 文件就应该是这样的：
				- ```
				  User-agent: *
				  Disallow: /
				  ```
				- 这里的 `Disallow: /` 表示禁止爬取整个网站。
					- 你也可以设定更复杂的规则，例如只允许特定的机器人访问特定的部分，或者禁止特定的机器人访问特定的部分。只需在文件中添加更多的 `User-agent` 和 `Disallow` 行即可。
	- 需要注意的是， *robots.txt* 文件并不是强制性的。也就是说，即使你在文件中写明了禁止所有机器人访问，也仍然可能有机器人无视这个文件，硬闯进你的网站。因此，对于你真正想保护的内容，你还需要采取其他的安全措施，如使用密码保护等